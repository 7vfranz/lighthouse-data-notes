{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Project Breakdown\n",
    "1. regression problem - Predicting flight delays\n",
    "    * predict delay of flights 1 week in advance\n",
    "    * R^2 max by students is 0.7\n",
    "    * don't predict by the minute - but predict in hours~ \n",
    "    * best is probably classification - delayed or not, or multi-class\n",
    "    * start with classification instead of building a regression of how much it is delayed by\n",
    "    * feature engineering - is most of the work\n",
    "    * sampling of data base - over 1 million rows \n",
    "    * mostly for data scientist/machine learnign role\n",
    "    * some data in training - not allowed to use in test \n",
    "    * table in flights test - will be more relevant - only things known 1 week in advanced\n",
    "    * e.g. forecast data from past not usually available in API (use actual values)\n",
    "    * can get lat/lon for example from an api\n",
    "    * compare train vs test\n",
    "    * for every row in a flight should have predicted_delay - should be equal to the flights test\n",
    "    * training data from past year to flights_test - only January \n",
    "    * always use WHERE for postgres query -> save results as a csv\n",
    "    * typically 100,000 rows is good\n",
    "    * by thursday - should have flight tests done\n",
    "    * has ground truth - predictionns vs results\n",
    "    * leave thursday for test set\n",
    "    * Work flow\n",
    "        * iterative\n",
    "        * start with low complexity - linear regression first\n",
    "        * start with simple features - minimal set that are easy to pre-process\n",
    "        * begin with a linear regression - logistic regression or linear\n",
    "        * grounds you gives some results - that can be tuned - have something to present\n",
    "<br>\n",
    "\n",
    "2. Clustering NYC neighbourhoods\n",
    "    * unsupervised learning\n",
    "    * from JSON data \n",
    "    * lots of API uses\n",
    "    * prase nyc_geo - dataframe with borough/neighbourhood/lat/long\n",
    "    * join data with features from APIs\n",
    "    * cultural - foursquare, yelp, google, meetups\n",
    "    * visualize clusters and their relationships to their economic/demographic variables\n",
    "    * No ground truth \n",
    "\n",
    "<br>\n",
    "\n",
    "Github\n",
    "* try to parellelize\n",
    "* multiple tables/data sources, split EDA of each and come up with interesting insights\n",
    "* can work on different ML models - and or feature engineering strategies\n",
    "* work - on data/features other works on modeling/evaluation \n",
    "* can create a minimum viable product\n",
    "* separate data/feature engineering - work on modeling/evaluation\n",
    "* use separate python files - and not notebook\n",
    "* meet frequently  \n",
    "* how to avoid github conflicts:\n",
    "    * DO NOT work on the same code\n",
    "    * commit+push only working copies - no errors\n",
    "    * add useful commit messages\n",
    "    * work on separate files to avoid conflicts\n",
    "    * git pull frequently to avoid conflicts (local version less out of sync)\n",
    "    * add to version control - data not too large\n",
    "    * add to README if needed \n",
    "\n",
    "<br>\n",
    "\n",
    "Evaluation Criteria\n",
    "* present as if to a client\n",
    "* make it a story\n",
    "    * problem, dataset, how did you analyze the data set, what were the findings\n",
    "    * chronological reference for code\n",
    "    * explain how you analyzed the data\n",
    "    * no code at all\n",
    "    * 5 minutes - final project\n",
    "* Motivation -> Task -> modeling -> results -> conclusions \n",
    "* draw.io for schematics\n",
    "\n",
    "Code Quality\n",
    "* modularization\n",
    "    * different files for different types \n",
    "    * functions on unified code - short english description make a function\n",
    "    * repo \n",
    "        * data (raw and preprocessed)\n",
    "        * src\n",
    "            * modules (python files)\n",
    "            * tests\n",
    "        * experiments - uses functions in different files to stitch \n",
    "* readability\n",
    "    * docstrings\n",
    "    * comments for code blocks\n",
    "    * refactor code\n",
    "    * meaningful variable names used\n",
    "* robustness\n",
    "    * test your functions\n",
    "* efficiency\n",
    "    * save processed/trained model only recreate when needed\n",
    "* have python files for function that can be used as jupyter notebook\n",
    "* avoid re-training model, function train_model(x,y, force_refit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lhl_env38",
   "language": "python",
   "name": "lhl_env38"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
