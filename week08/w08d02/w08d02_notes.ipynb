{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deep Learning - Deep Neural Networks\n",
    "* just more layers \n",
    "* connection have weights\n",
    "* units have constant/threshold value \n",
    "* activation function - formula (ReLU) transforms to 0-infinity\n",
    "* adjust parameters on each unit - through gradient descent and backpropagation \n",
    "* deep reserved for - more than three layers of neurons (including input and output) - 2 hidden layers \n",
    "* forward .. back propagation? \n",
    "\n",
    "Different Architectures\n",
    "* [common architectures](https://srnghn.medium.com/deep-learning-common-architectures-6071d47cb383)\n",
    "* MLP (multilayer perceptron)\n",
    "    * every unit is connected to the next\n",
    "    * MLP can have many layers\n",
    "    * good for structured tabular data\n",
    "    * good base model for accuracy before trying more complex architectures\n",
    "* Convulutional Neural Networks (CNN)\n",
    "    * usually for computer vision using images as input\n",
    "    * captures spatial aspects of data\n",
    "    * 'convolutional' layers that tries to capture spatial patterns\n",
    "    * 'pool' layers that reduce scope of math work for future layers \n",
    "    * cycles through convolutions and pool - then last layer is joined and flattened (fully connected) out to be one long neural layer \n",
    "    * and passed through an MLP for an output\n",
    "* Recurrent Neural Networks\n",
    "    * good for sequential data\n",
    "    * neurons with RNN have a state - interpreted as memory\n",
    "    * if data is time-series it can take t-4,t-3 to predict t\n",
    "    * context of words can also be passed through\n",
    "* Hybrid Models\n",
    "    * combines different architecture types \n",
    "\n",
    "Convolutional Neural Networks\n",
    "* human vision, robots learning to cook through youtube\n",
    "* matches part of the image rather than entire thing \n",
    "* filtering, set a box/patch on the image and see how much it matches \n",
    "    * line up feature and image patch\n",
    "    * multiply each image pixel by feature pixel\n",
    "    * sum\n",
    "    * divide by total number of pixels \n",
    "* (x) - convolution\n",
    "* maps where 'feature' patch matches in the larger image\n",
    "* one image becomes a stack of filtered images\n",
    "* pooling is shrinking the filtered image \n",
    "    * pick a window size (2x2 or 3 pixels)\n",
    "    * pick a stride (usually 2 pixels) \n",
    "    * walk window across the filtered image\n",
    "    * take the maximum value\n",
    "* ends with similar pattern but smaller\n",
    "* less sensitive to position - only takes the maximum value\n",
    "* will pick up even if images are translated a bit\n",
    "* Normalization\n",
    "    * negative to 0\n",
    "    * 'rectified linear units (ReLU)\n",
    "    * stack of images with no negative values\n",
    "* convolution -> relU -> Pooling\n",
    "* stacked together, gives an array of pixels\n",
    "* can repeat stacking (deep stacking)\n",
    "    * each time the image gets smaller\n",
    "* Final layer = fully connected layer - every value gets a vote\n",
    "* value gets high weights for specific class/output\n",
    "* can have many hidden units also after flattening\n",
    "* Backprop\n",
    "    * error = right answer - actual answer\n",
    "    * error goes through gradient descent - adjusted up and down (step size/learning rate) to see how error changes\n",
    "    * find weight with lowest error\n",
    "* Hyperparameters\n",
    "    * Convolution\n",
    "        * number of features\n",
    "        * size of features\n",
    "    * Pooling\n",
    "        * window size\n",
    "        * window stride\n",
    "    * Fully connected\n",
    "        * number of neurons\n",
    "* Architecture\n",
    "    * how many layers, and of each\n",
    "    * at what order\n",
    "* Can be used with 2d or 3d data\n",
    "* things close together must be closely related than things far away\n",
    "* e.g. sound - bass, treble, etc, can look like an image\n",
    "* text - position in sentence as columns, words in dictionary as rows, can do one whole column\n",
    "* Limitations\n",
    "    * things next to each other matters a lot\n",
    "    * only capture local spatial patterns in data\n",
    "    * data should be able to be made to look like an image\n",
    "    * otherwise less useful\n",
    "    * a good tell - if columns in the data can be swapped around (no order) - then CNN will be of less use\n",
    "\n",
    "**Recurrent Neural Networks**\n",
    "* Long Short-Term Memory Network\n",
    "* text, speech, audio, time-series\n",
    "* can have prediction units from t2, t3, t4\n",
    "* if missing a few weeks - it removes 'yesterday' or 'two days' ago, and uses it from when last available\n",
    "* in a sentence - could be word before\n",
    "* all votes go through a 'squashing function' - tanh, larger values become 1 (activation function)\n",
    "* short-term memory only goes back one sentence or time point\n",
    "* needs more 'memory' - to go back more steps back\n",
    "* (+) - element by element addition\n",
    "* (x) - element by element multiplication\n",
    "    * gating - to let signal come through or block it\n",
    "    * 0, 0.5, 1 multiplication\n",
    "* prediction - gets pass through - but held on through in the next pass through - the gate allows some to be remembered- added through prediction, and some forgotten\n",
    "* another neural network goes through forgetting\n",
    "* another neural network also goes through 'selection' another gate \n",
    "* new information -> predictions -> ignore -> goes through memory -> all predictions squashed -> goes through a selection process \n",
    "* all inputs goes through - selection, forgetting, ignoring, prediction\n",
    "* LSTM can look back many time steps\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From Lecture\n",
    "* unversal approximation theorem - mathematical theory of artificial neural networks, can approximate and model anything\n",
    "* hard to understand why it picks those parameters\n",
    "* excels with lots of data\n",
    "* black box learning algorithm - \n",
    "* working with image data use Pillow - rotates, zooms, - essentially data augmentation - creating new images - but can be done through keras automatically\n",
    "* done through directory and folders for classes\n",
    "* number of parameters/units depends on how much data you have\n",
    "* if accuracy is going high, but validation loss is stabilized - likely overfitted\n",
    "* finetuning - tf.keras.applications\n",
    "* selecting different network\n",
    "* input image size needs to be a specific number \n",
    "\n",
    "Fine Tuning\n",
    "* when adapting - need to add layers - and those layers are the only ones that get trained \n",
    "* weights of base models are frozen - already trained\n",
    "* base_model.trainable = False\n",
    "* don't need much more data "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lhl_env38",
   "language": "python",
   "name": "lhl_env38"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
