{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reinforcement Learning\n",
    "* reinforcement learning loop\n",
    "* state(t) -> agent -> action(t) -> reward(t) + state(t+1) \n",
    "* environment sets the initial state and reward  \n",
    "* maximize the expected return \n",
    "* RL based on reward hypothesis - maximize expected return (expected cumulative reward)\n",
    "* best behaviour - to maximize expected cumulative reward\n",
    "* calculate expected reward for each state\n",
    "\n",
    "Problems with expected reward\n",
    "* can't always add\n",
    "* long term and short-term goals\n",
    "* via gamma parameter value between 0-1\n",
    "* larger gamma = smaller discount - agent cares more about long-term reward\n",
    "* smaller gamma = larger discount - agent chooses more short-term reward\n",
    "* each reward will be discounted by gamma to exponent of time step\n",
    "* expected reward(t+n) * gamma + constant\n",
    "\n",
    "Flow\n",
    "* start with state space - current environment\n",
    "* action space - all possible actions within a given environment\n",
    "    * can be discrete - n number of possible action\n",
    "    * continuous - infinite e.g. self-driving\n",
    "    * RL can learn both\n",
    "\n",
    "Exploration/Exploitation tradeoff\n",
    "* exploration - trying more random actions to find more information about the environment\n",
    "* exploitation - exploiting known information to maximize reward\n",
    "* explore at the beginning - exploit towards the end\n",
    "\n",
    "Two Methods for maximizing return\n",
    "* goal is to find 'optimal policy' - that maximizes expected return \n",
    "1. Policy Based methods \n",
    "* using NN (DQN)\n",
    "2. Value based methods\n",
    "* using a value function to decide what action to take\n",
    "* using more classical math formula to find the best state in the model\n",
    "* Q-Table \n",
    "\n",
    "Flappy Bird RL\n",
    "[source_code](https://colab.research.google.com/drive/1BDFfNsvBateOuMh2pTRWNBgnsrKFXUBG?usp=sharing#scrollTo=6nMWT2Z-ejmH)\n",
    "* has gym - for reinforcement learning\n",
    "* keras-rl2 - for reinforcement learning \n",
    "* coding in neural network\n",
    "    * sequential\n",
    "    * accepting input - all dense layers \n",
    "    * then flatten \n",
    "    * then dense - linear to 0 or 1\n",
    "* needs build_agent - with policy, memory, dqn\n",
    "* policy - EpsGreedyQPolicy() - for greedy \n",
    "    * value_max - 0-1, 1 = max exploration, 0.5 half half\n",
    "    * degrades over time value_min\n",
    "* remove flappy_bird_gym folder from original\n",
    "* del model before building an agent\n",
    "\n",
    "--------\n",
    "Q-learning \n",
    "* value based\n",
    "* Q = quality of action\n",
    "* indicates reward for each given action given a state in a game\n",
    "* no neural network \n",
    "* initialize q -> choose action -> perform -> measure reward -> update q\n",
    "* until achieving optimal policy \n",
    "* 1. init table with rows of states and columns of actions, values as expected reward at each\n",
    "* 2. choose an action - current state s based on current q-value\n",
    "    * choose random action\n",
    "    * perform the random action\n",
    "* 3. update q table \n",
    "    * based on Bellman Equation - how it is optimized\n",
    "    * current q value\n",
    "    * change in Q value = Reward + discountRate*otherQs - Q previous\n",
    "    * now a new Q\n",
    "* [in code](https://colab.research.google.com/drive/1dBUHvIeB0ExNIrCcG6m2H_N3MAR7zz71#scrollTo=8lXPoiJgJGHy)\n",
    "* q_table is the introduction to reinforcement learning\n",
    "* slowly decay exploration - and start exploitation\n",
    "* reward is faster - but needs a q table - that maps every possible state and action\n",
    "* can become infinite long with complex problems - needs neural network\n",
    "* NN approximates the qtable\n",
    "\n",
    "## Notes\n",
    "* check for stable baselines\n",
    "* agents PPO \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lhl_env38",
   "language": "python",
   "name": "lhl_env38"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
