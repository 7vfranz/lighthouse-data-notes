{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Collaborative Filtering - Recommendations\n",
    "* 1. Memory-based\n",
    "* 2. Model based\n",
    "\n",
    "Data Set\n",
    "* needs set of items\n",
    "* set of users - that react to the items\n",
    "* explicit - like likes/dislikes\n",
    "* implicit - viewing item, added to wish list, time spent\n",
    "* seen in the form of a matrix \n",
    "* rows = ratings given by a user\n",
    "* columns = contain ratings received by an item\n",
    "* most cells will be empty - as users only rate a few items (sparse matrix)\n",
    "\n",
    "Steps Involved\n",
    "* determine which users are similar to each other \n",
    "* determine rating for a given item based on ratings of similar users\n",
    "* accuracy of ratings - via error - RMSE or MAE\n",
    "\n",
    "#### Memory Based\n",
    "Finding Similar USers\n",
    "* find users similar to U (User) who rated the item (I)\n",
    "* calcualte rating (R) based on ratings from previous step\n",
    "* plotting a user's rating on a certain item - calculate distances between users\n",
    "* format is basically a list of users (outer) with a list of ratings (inner) for movies\n",
    "* euclidean dsitance \n",
    "* or consider the angle from the origin (cosine similarity)\n",
    "* low angle - higher similarity/smaller distance\n",
    "* high angle - lower similarity/larger distance\n",
    "* cosine angle - ranges from 0-180, into -1 to 1\n",
    "* cosine distance - higher value for higher angle (lower similarity)\n",
    "* scipy spatial.distance.cosine(a,b)\n",
    "* can normalize/adjust data to remove the individual user preferences - measuring the average of ratings and subtracting that from all ratings\n",
    "* 'centred cosine' finding angle of adjusted vectors, done when there's a lot of missing values\n",
    "* could impute missing values with average rating by each user - but must also adjust current ratings - to avoid bias/inaccuracies \n",
    "\n",
    "Calculating Ratings\n",
    "* after finding similar users\n",
    "* predict ratings as average rating of top n (5-10) users that are most similar\n",
    "* could also do weighted average - with more weight to users with most similarity \n",
    "\n",
    "User-Based vs Item-Based Collaborative Filtering\n",
    "* similar mathematically - just different conceptually\n",
    "* User Based\n",
    "    * rating for item - is found by picking out N users from similarity list who has rating the item and then calcualte ratings based on these N-ratings\n",
    "* item-based\n",
    "    * for item - with set of similar items based on rating vectors with item ratings by a user - who hasn't rated it\n",
    "    * found by picking out N items with similarity with I that a user U has rated - and find rating based on these N ratings\n",
    "* item based is ususally more stable and faster than user-based \n",
    "* library - Surprise\n",
    "\n",
    "#### Model Based \n",
    "* reduce or compress large and sparse user-item matrix \n",
    "* using matrix factorization or autoencoders\n",
    "* Matrix factorization - Dimensionality Reduction\n",
    "    * break large matrix to smaller ones\n",
    "    * e.g. factoring 12 to 4,3,2,6\n",
    "    * reduce large sparse matrix into two matrices \n",
    "    * get similar item vectors (i,j)\n",
    "    * gives latent factors about users/items\n",
    "    * too many latent factors and recommendations become too specific/overfitted\n",
    "\n",
    "Algorithms for Matrix Factorization\n",
    "* SVD - singular value decomposition, PCA\n",
    "* Autoencoders for Neural Networks\n",
    "\n",
    "Using python\n",
    "* numpy and scikit-surprise\n",
    "* load dataset.load_builtin()\n",
    "* can specify user_based, min_support \n",
    "* can also use recommender.algo\n",
    "* can use GridSearch in combination with surprise\n",
    "* using KNNWithMeans - which is similar to centeredCosine similarity\n",
    "* can also use SVD\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From Lecture\n",
    "* recommender based on historical viewing of two users\n",
    "* utility matrix - for every user (row) - column (items) that they have used or interacted with (e.g. columns of movies)\n",
    "* cells of ratings, clicks, etc. can be combined as weighted average\n",
    "* usually very sparse - with lots of missing/unknowns\n",
    "* if no missing - job is done - just sort and recommend top\n",
    "* collaborative approach essentially filling missing - things that they will 'enjoy' - and then compare ratings vs predicted ratings - to optimize\n",
    "* other measure more important - is whether users actually engage with the recommendations - can only be observed with A/B testing \n",
    "* can have billions of users in a row, x thousands of columns for movies\n",
    "* can have one utility matrix for each country, distribution of movies/users are different\n",
    "\n",
    "Content Based Recommender\n",
    "* no collaboration between content and users\n",
    "* only looks at features of the content - what content is similar \n",
    "* can recommend even without lots of users\n",
    "* can capture unique tastes of users - no interaction b/w users\n",
    "* easier to explain why recommendations are the way they are\n",
    "* can recommend new items - no priors from user\n",
    "* Disadvantage\n",
    "    * initial set up is expensive\n",
    "    * feature acquisition for all catalogue\n",
    "    * low diversity: hardly recommend an item outside of the user's preference\n",
    "    * Cold start - no information about new users what to do\n",
    "\n",
    "#### Collaborative - Memory Based\n",
    "\n",
    "* Memory based collaborative \n",
    "    * similarities between users and items predicts new rating for an item\n",
    "    * taking weighted average of ratings from the similar group\n",
    "    * memorizes utility matrix, no modeling\n",
    "\n",
    "* User-to-User\n",
    "    * how similar is User 1 to everyone else\n",
    "    * content consumed by U1 - compared to  other Users \n",
    "    * calculate similarity (cosine, euclidean distance) between vectors (e.g. users ratings from a bunch of movies)\n",
    "    * rating for movie U1 hasn't consumed - based on weighted average of ratings with other Users ratings\n",
    "    * based on user similarity - aggregated scores from items\n",
    "    * combined item-to-item \n",
    "    * missing values found using: ~user1.isna()\n",
    "\n",
    "* Item-to-Item\n",
    "    * similar to content-based\n",
    "    * but also takes into account user interaction with items\n",
    "    * invented at amazon\n",
    "    * taking the row vectors - downward across users - for a given movie\n",
    "    * only row vectors where we actually have a value\n",
    "    * different from content-based because it takes into consideration user ratings or inputs\n",
    "    * rating for a movie (not seen) - weighted average rating of every users to similar movies\n",
    "    * based on item similarity - with aggregated scores from users\n",
    "    * usually combined with user-to-user\n",
    "\n",
    "* can get recommendation from u-to-u and i-to-i and pick common recommended\n",
    "* often used all together because - content-based/collaborative - especially for users that just started \n",
    "* viral content - not as good with collaborative - because no matter what 'cluster' a user is in - it should be recommended \n",
    "* MAE/RMSE of predicted scores might not always be accurate \n",
    "* will need to use A/B test paired with stats based hypothesis testing\n",
    "* easier with users - but if not available - must use MAE/RMSE \n",
    "\n",
    "Diversity \n",
    "* rather than just taking top case similarity\n",
    "* take some less similar suggestions within the 10 same ones\n",
    "* exploration instead of exploitation\n",
    "\n",
    "Novelty\n",
    "* new or unknown items\n",
    "* need balance here \n",
    "* popular items wont be surprising, but surprises might not be good \n",
    "\n",
    "Responsiveness\n",
    "* how fast the system changes as new user/item interactions arrive\n",
    "* recommendations can get stale \n",
    "* but more updates takes more resources\n",
    "* persistence: how long to keep an item in the recommendations, not being clicked can be removed \n",
    "\n",
    "Non-algorithmic\n",
    "* stimulating demand\n",
    "* not always based on algorithms\n",
    "* e.g. Stranger Things or new movies coming out \n",
    "\n",
    "Types of Data\n",
    "* not always direct data (ratings, thumbs up)\n",
    "* consumers don't usually use explicit data\n",
    "* collected from your behaviour - implictly - mouse clicks, purchases, time spent doing something\n",
    "\n",
    "#### Collaborative - Latent Factors\n",
    "* actually models the data and provides approximation\n",
    "* still uses ultility matrix\n",
    "* but uses both - u-to-u and i-to-i similarity\n",
    "* similar to PCA or SVD\n",
    "* reducing the dimensions\n",
    "* Movie ratings -> matrix factorization --> 1. user attributes 2. movie attributes\n",
    "* multiplying user x movie attributes gives matrix factorization\n",
    "* interpolate - missing in utility matrix imputed by multiplying, dot product U and M - getting a complete utility matrix \n",
    "* randomly initialize U and M -> then compare to target utility matrix (assuming all value filled in) -> gradient descent -> to get closer to target matrix\n",
    "* get error - MSE - loss function, minimize by changing the latent variables\n",
    "* missing values ignored in the cost-function calculation\n",
    "* once optimized with values you do have - can then fill in missing values \n",
    "\n",
    "SVD (singular value decomp) example\n",
    "* similar to PCA\n",
    "* M - movies in rows with latent variables columns\n",
    "* U - users in rows with latent variables in columns\n",
    "* same latent variables in U and M"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lhl_env38",
   "language": "python",
   "name": "lhl_env38"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
