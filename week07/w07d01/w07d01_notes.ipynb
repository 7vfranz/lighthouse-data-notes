{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pickling \n",
    "* Pickling - turns python object hierarchy into a 'byte stream' dumped into a file - uses - 'dump'\n",
    "* turns to 0,1 - flattens it \n",
    "* Unpickling - convert byte stream back to object hierarchy - uses - 'load'\n",
    "* errors: picklingError - object not supported for pickling\n",
    "* Unpickling error - bad/corrupted data\n",
    "* good for saving complicated data, easy to use, not easily readable\n",
    "* bad for non-python, unpickling malicious sources \n",
    "\n",
    "\n",
    "pickling a list, wb is bytes format:\n",
    "```\n",
    "my_list = [1,2,3,4]\n",
    "with open('datafile.txt', 'wb') as fh: \n",
    "     pickle.dump(mylist, fh)\n",
    "```\n",
    "\n",
    "unpickling, rb for read bytes\n",
    "```\n",
    "pickle_off = open('datafile.txt', 'rb')\n",
    "emp = pickle.load(pickle_off)\n",
    "print(emp) \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Joblib\n",
    "* used for large numpy arrays internally\n",
    "* has similar joblib.dump() and joblib.load()\n",
    "* can compress files setting a compress= argument\n",
    "    * default zlib, but can choose gzip, bz2, lzma, xz\n",
    "\n",
    "```\n",
    "# to dump\n",
    "import joblib\n",
    "joblib.dump(to_persist, filename) \n",
    "\n",
    "# to reload\n",
    "joblib.load(filename)\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Walkthrough](https://machinelearningmastery.com/save-load-machine-learning-models-python-scikit-learn/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/lhl_env38/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save Model Using Pickle\n",
    "import pandas\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pickle\n",
    "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "dataframe = pandas.read_csv(url, names=names)\n",
    "array = dataframe.values\n",
    "X = array[:,0:8]\n",
    "Y = array[:,8]\n",
    "test_size = 0.33\n",
    "seed = 7\n",
    "X_train, X_test, Y_train, Y_test = model_selection.train_test_split(X, Y, test_size=test_size, random_state=seed)\n",
    "# Fit the model on training set\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'finalized_model.sav'\n",
    "pickle.dump(model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7874015748031497\n"
     ]
    }
   ],
   "source": [
    "loaded_model = pickle.load(open(filename, 'rb'))\n",
    "result = loaded_model.score(X_test, Y_test)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7874015748031497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/lhl_env38/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Save Model Using joblib - outdated not really used - stick with pickle\n",
    "import pandas\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import joblib\n",
    "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "dataframe = pandas.read_csv(url, names=names)\n",
    "array = dataframe.values\n",
    "X = array[:,0:8]\n",
    "Y = array[:,8]\n",
    "test_size = 0.33\n",
    "seed = 7\n",
    "X_train, X_test, Y_train, Y_test = model_selection.train_test_split(X, Y, test_size=test_size, random_state=seed)\n",
    "# Fit the model on training set\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, Y_train)\n",
    "#\n",
    "#\n",
    "# save the model to disk\n",
    "filename = 'finalized_model.sav'\n",
    "joblib.dump(model, filename)\n",
    " \n",
    "# some time later...\n",
    " \n",
    "# load the model from disk\n",
    "loaded_model = joblib.load(filename)\n",
    "result = loaded_model.score(X_test, Y_test)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tips for saving models:\n",
    "* Python version from serializing to loading must be the same\n",
    "* library version need to be same when serializing and deserializing\n",
    "* Manual Serialization - manually output parameters to use them directly later in sklearn or another platform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pipelines\n",
    "[walkthrough](https://web.archive.org/web/20210507043615/https://iaml.it/blog/optimizing-sklearn-pipelines)\n",
    "* chains multiple estimators into one (sklearn data processing and modeling steps)\n",
    "* if there's a fixed sequence of steps in processing data\n",
    "* convenient and encapsulation (fit and predict), joint parameter selection (grid search over the parameters of all estimators in the pipeline at once)\n",
    "* safety - avoid leaking statistics from test data into the trained model in cross-validation\n",
    "* all objects in a pipelines (except the last) must be 'transformers' - have a .transform() method\n",
    "* last estimator can be any type (transformer, regressor, or classifer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From Lecture\n",
    "* ugly code .fit and .transform on different objects\n",
    "* proprocessing and modeling - is distributed and error prone\n",
    "* gridsearch can only be used on model class - can be done to different number of components or scaling methods\n",
    "* scaling needs fit and transform \n",
    "* ends classifier/regressor with .predict\n",
    "* can create own Pipeline class \n",
    "* must all be sklearn \n",
    "* but can create own \n",
    "* fit [:-1] - scalers, because the last step is the classifier\n",
    "* [-1] is for fitting with regressor/classifer\n",
    "* return self - an sklearn convention\n",
    "* can later visualize sklearn \n",
    "\n",
    "Feature unions\n",
    "* branches in our process\n",
    "* different feature engineerings on different branches \n",
    "* which can be joined that the end\n",
    "* but applies still to all features coming in\n",
    "* but can split - PCA - kbest - then join the features after\n",
    "\n",
    "Column Transformers\n",
    "* similar to a feature union\n",
    "* numerical columns\n",
    "    * impute means, stnadard scaler\n",
    "* categorical columns\n",
    "    * impute missing with mode\n",
    "    * one hot encode\n",
    "* fit model on resulting features \n",
    "* takes dataframe, and outputs a numpyarray\n",
    "\n",
    "Visualizing a Pipeline\n",
    "* set_config(display='diagram')\n",
    "* or saved as html file\n",
    "\n",
    "Gridsearch Hyperparameter tuning\n",
    "* paramgrid - but now 'pipelineStep_ _ parameter':[param list]\n",
    "* if nested under feature_union: features_ _pca_ _n_components\n",
    "* two double underscores for the name in pipeline and the name in feature_union\n",
    "* verbose=1 says how many fits\n",
    "* hyperparameters - increasing values \n",
    "\n",
    "Custom Class Pipeline\n",
    "* e.g. log transform a column\n",
    "* create a new class\n",
    "* LogTransformer(BaseEstimator, TransformerMixin):\n",
    "    * needs __init__, fit, and transform\n",
    "* transform is where it changes\n",
    "* fit is if you need something from the training data - getting mean. \n",
    "* if it's just a transform: \n",
    "* faster way is to create a function, and use \"FunctionTransformer(func)\n",
    "* if you don't need a .fit  \n",
    "\n",
    "Model Persistance\n",
    "* employment vs deployment - two different things\n",
    "* once model is done - just pickle and pass through to someone else (web developer)\n",
    "* save as .pickle\n",
    "* pickle faster than joblib 3.8+ python\n",
    "* doesn't save code only save object\n",
    "* recreates pipeline - plugs in values from steps\n",
    "* needs to be the same version - in case of changes in attribute names e.g. coef_ to weights\n",
    "* anaconda environments need to be the same - can export the anaconda environments along with pickled file\n",
    "* custom classes needs to be redefined where the pipeline is running, doesn't save as object \n",
    "* on server - need to have the same sklearn, and add the custom code "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lhl_env38",
   "language": "python",
   "name": "lhl_env38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
